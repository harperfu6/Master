タッチパネルの普及により，ペンや指を用いた手書きジェスチャを入力として用いるアプリケーションが多く開発されている．
手書きジェスチャ入力を実現するためには，手書きジェスチャを認識するための認識アルゴリズムを実装する必要がある．
手書きジェスチャを認識するための既存アルゴリズムの多くはライブラリにより提供されているが，認識に必要な学習データの数が膨大であったり，認識率及び認識速度の性能が望んだものでない場合がある．また，自分で実装するには専門的な知識が必要である．既存の手書きジェスチャ認識アルゴリズムの1つである\$1はこれらの問題を解決したアルゴリズムである．その特徴は，少ない学習データにおいて高い認識率を示す，認識速度が速い，ロバスト性が高いといったものが挙げられる．また，アルゴリズムが簡潔であるため，様々な開発環境において実装されてきた．しかしながら，ユーザ調査により，アプリケーションユーザは，手書きジェスチャの形状や書き順が同じでも，大きさ，向き，位置の違いを利用したジェスチャを入力したいという要望があることがわかった．\$1を始め\$1を改良した多くのアルゴリズムは，認識率や認識速度の低下を避けるため，ユーザが定義するこれらの手書きジェスチャを識別できるようなアルゴリズムとなっていない．
そこで本研究にて，認識率や認識速度の低下を抑えつつ，手書きジェスチャの形状や書き順が同じでも，大きさ，向き，位置の違いを識別可能なアルゴリズム\$Vを開発した．\$Vは\$1を拡張し，保管されている学習データをもとに，入力データと学習データにおいて，大きさ，向き，位置の類似度を計算するジェスチャを選ぶことによって認識速度の低下を抑えた．また，大きさ，向き，位置の特徴量に重み付けをすることによって認識率の低下を抑えた．\$Vは\$1に簡単な数式からなるアルゴリズムを加えるだけであるため，アプリケーション開発者は，本論文において示されるアルゴリズムを自身のシステムに組み込むことにより，大きさ，向き，位置の違いを利用した手書きジェスチャを入力として用いるようなアプリケーションを容易に開発することができる．
また，我々は\$Vの性能評価のために既存アルゴリズムとの比較実験を行い，認識率，認識速度及びアルゴリズムとしての識別性能において高い性能を示し，\$Vの有用性を示した．