\chapter{結論}
本論文にて，ユーザ定義手書きジェスチャを認識するアルゴリズムである\$Vを開発した．
本論文にてまず，ユーザ調査を行い，アプリケーションユーザは，手書きジェスチャの形状や書き順が同じでも，大きさ，向き，位置の違いを利用したジェスチャを入力したいという要望があることがわかった．これをユーザ定義手書きジェスチャとし，それらを認識するためのアルゴリズムを開発した．
\$Vは\$1を拡張し，\$1のように，アルゴリズムが簡潔である，少ない学習データにおいて高い認識率を示す，認識速度が速い，ロバスト性が高いと行った特徴を持ちながら，\$1とは違い，大きさ，向き，位置に関して識別可能にした．
その際，大きさ，向き，位置に関して不変な\$1と比べて，認識速度及び認識率の低下を抑えるために，ジェスチャグループを作成し，類似度計算するジェスチャの数を減らす，かつ保管されている学習データの類似度をもとに，識別するために必要な特徴量を選定するという手法を用いた．
また，識別するために必要な特徴量を選定する上で，それらの特徴量が識別するためにどれくらい必要であるかを重みによって表現することによって，より尤度の高い認識を可能にした．アプリケーション開発者は，本論文にて示した．学習データ間の類似度と最適な重みの関係式を用いることによって，そのような認識アルゴリズムを容易に実装できる．
評価実験においては，93\%の認識率を示し，N-best Listsの1番目と2番目のスコアの差は0.24であり，高い認識率，識別性能を示した．また，認識速度は\$1と有意差がなく高速であることを示した．また，大きさ，向き，位置が識別可能な既存アルゴリズムと比較し，認識率及び認識速度において高いパフォーマンスを示した．
\$Vアルゴリズムが簡潔であるため，ジェスチャ認識アルゴリズムのライブラリが提供されていない開発環境においても実装可能であるだけでなく，特に手書きジェスチャ認識への深い知識を持たないアプリケーション開発初学者にも，自身のシステムに容易に組み込むことが可能である．
また，\$Vの手書きジェスチャ認識としての改善点及び応用可能性を示した．